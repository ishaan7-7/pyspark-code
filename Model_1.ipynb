{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIPAGI6aABTb",
        "outputId": "2ff12761-f578-4d1d-8731-01ac65b758bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-10 17:21:17--  https://archive.apache.org/dist/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz\n",
            "Resolving archive.apache.org (archive.apache.org)... 65.108.204.189, 2a01:4f9:1a:a084::2\n",
            "Connecting to archive.apache.org (archive.apache.org)|65.108.204.189|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 299360284 (285M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.3.2-bin-hadoop3.tgz’\n",
            "\n",
            "spark-3.3.2-bin-had 100%[===================>] 285.49M  13.1MB/s    in 23s     \n",
            "\n",
            "2025-08-10 17:21:41 (12.7 MB/s) - ‘spark-3.3.2-bin-hadoop3.tgz’ saved [299360284/299360284]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!rm -rf spark-3.3.2-bin-hadoop3 spark-3.3.2-bin-hadoop3.tgz\n",
        "\n",
        "!wget -O spark-3.3.2-bin-hadoop3.tgz https://archive.apache.org/dist/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz\n",
        "\n",
        "!tar -xzf spark-3.3.2-bin-hadoop3.tgz\n",
        "\n",
        "!pip install -q findspark pyspark tensorflow numpy matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-11-jdk -qq > /dev/null"
      ],
      "metadata": {
        "id": "A0evKWTOAKm1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.2-bin-hadoop3\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").appName(\"SignalAnomalyDetection\").getOrCreate()"
      ],
      "metadata": {
        "id": "rK9FZawGAORc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNks091ZASMi",
        "outputId": "eb3588ef-c7b6-404b-c111-894bb331391b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, unix_timestamp\n",
        "from pyspark.ml.feature import VectorAssembler, MinMaxScaler\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "df = spark.read.option(\"header\", True).csv(\"/content/drive/My Drive/Colab Notebooks/Book1.csv\")\n",
        "\n",
        "signal_cols = [f\"signal_{i}\" for i in range(1, 61)]\n",
        "df = df.select(col(\"Timestamp\"), *[col(c).cast(DoubleType()) for c in signal_cols])\n",
        "df = df.withColumn(\"timestamp_secs\", unix_timestamp(\"Timestamp\", \"MM/dd/yyyy HH:mm:ss:SSSSSS\"))\n",
        "\n",
        "assembler = VectorAssembler(inputCols=signal_cols, outputCol=\"features_raw\")\n",
        "df_vec = assembler.transform(df)\n",
        "\n",
        "scaler = MinMaxScaler(inputCol=\"features_raw\", outputCol=\"features\")\n",
        "scaler_model = scaler.fit(df_vec)\n",
        "df_scaled = scaler_model.transform(df_vec)"
      ],
      "metadata": {
        "id": "x4-YdfH_AYul"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_scaled.limit(10).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey26lC_HAduR",
        "outputId": "fd6f953f-aefc-49f1-da0b-a6960ea63b2f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------------+------------------+-------------------+------------+------------------+-------------------+--------------------+-------------------+--------------------+------------+------------+-------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+-------------------+------------------+-------------------+--------------------+------------+------------+-------------------+------------------+-------------------+-------------------+-------------------+------------+--------------------+------------------+-------------------+-------------------+------------------+------------+------------+-------------------+------------------+-------------------+-------------------+------------+------------+-------------------+-------------------+-------------------+------------------+------------+--------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+-------------------+------------------+-------------------+------------------+-------------------+--------------+--------------------+--------------------+\n",
            "|           Timestamp|           signal_1|          signal_2|           signal_3|    signal_4|          signal_5|           signal_6|            signal_7|           signal_8|            signal_9|   signal_10|   signal_11|          signal_12|          signal_13|          signal_14|          signal_15|          signal_16|   signal_17|   signal_18|          signal_19|         signal_20|          signal_21|           signal_22|   signal_23|   signal_24|          signal_25|         signal_26|          signal_27|          signal_28|          signal_29|   signal_30|           signal_31|         signal_32|          signal_33|          signal_34|         signal_35|   signal_36|   signal_37|          signal_38|         signal_39|          signal_40|          signal_41|   signal_42|   signal_43|          signal_44|          signal_45|          signal_46|         signal_47|   signal_48|           signal_49|          signal_50|          signal_51|          signal_52|          signal_53|   signal_54|   signal_55|          signal_56|         signal_57|          signal_58|         signal_59|          signal_60|timestamp_secs|        features_raw|            features|\n",
            "+--------------------+-------------------+------------------+-------------------+------------+------------------+-------------------+--------------------+-------------------+--------------------+------------+------------+-------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+-------------------+------------------+-------------------+--------------------+------------+------------+-------------------+------------------+-------------------+-------------------+-------------------+------------+--------------------+------------------+-------------------+-------------------+------------------+------------+------------+-------------------+------------------+-------------------+-------------------+------------+------------+-------------------+-------------------+-------------------+------------------+------------+--------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+-------------------+------------------+-------------------+------------------+-------------------+--------------+--------------------+--------------------+\n",
            "|01/01/2025 00:00:...| 1.4756345774376527|1.2149476631221423| 0.1030611675125446|-0.433505765|0.6256836515225125| 0.7135760574727875|         0.967352831| 1.0122873694176358| 0.17194188245559006|-0.907417401|-0.355572953|       -1.295686533| 0.3810875419293469| 0.8771679896069986| 1.0015304651682606|       -0.104175499|-0.857885213|-1.053971402| 0.6324717405299112|        0.59885149|       -0.417816288|        -0.187049036|-0.160240451|-1.223927081| 0.1764982481112031|0.9347954202521003| 1.7198642752687776| 0.4163551333766875|       -0.370812251| -0.59414135|        -0.618926333|      -0.011398986| 1.1870587244048831|        0.656790127|      -0.101648379|-1.216456654|-0.801472914| 0.2797538580643347|0.6639709146718943| 2.3711360816673643|        0.080738521|-1.027168776|-0.884162972|0.40296268259237106|         0.00885228| 1.9353364785893152|      -0.370880559|-0.235929067|        -0.290264485|       -1.003251404|       -0.223574712| 0.8177269988325511|        1.033458935|-0.871536913|-0.484212796|0.10307431118026911|0.6156966698041536| 1.1295661738272966|0.6530674628441171| 0.7650090264115111|    1735689600|[1.47563457743765...|[0.68515320033510...|\n",
            "|01/01/2025 00:00:...|  1.724416933672154|1.3337201464014758|       -0.039688168|-0.102607333|      -1.033460045| 0.6481829523422505|  0.2869962230457725| 0.7927898252930937|          0.06861863|-0.689345985|-1.843266961|       -1.713558486| 1.3287284199902738| 0.8989175363926001| 1.0960480041135283|        0.033854578| -0.77390239|-0.378823788| 0.7257788580888522|1.6166891706702056| 0.7636709529062398|0.057991912532459305|-0.819550213|-1.068633827|         0.96963381|0.5034894464813484|        1.170440661|0.16078844174346593|       -0.928383631|-0.716798506|        -0.266251918|0.6578431514615407| 1.0429718494360618|        0.624016044|       -3.20477E-4|-0.194591548|-0.293197627|       -0.226777806|0.9007250083250498| 0.8856150442744163|0.14636094852721673|-0.742871954|-0.460110356|       -0.442225002| 1.5684748244482054|  1.093301140543795|      -0.057065835| -1.49959739|        -0.916769283| 0.9233741782454269|       -0.460236864| 1.3167175275881986| 0.7193414191632469|-0.887454921| -0.93156576|       -1.186235709|      -0.075674914|0.10011924955422713|0.6467953399767801|       -0.671662126|    1735689601|[1.72441693367215...|[0.76467159465325...|\n",
            "|01/01/2025 00:00:...|        0.887286076|      -0.040051251|        0.055738346|-0.528965373|      -1.899521273|       -0.926502876|0.022637206805527943|        1.820368612|0.019577001158530838|-0.926667581|-0.910555113|       -0.010506011| 1.3614333329185924| 0.5062147732127031| 1.6429656721120196|       -0.941611652|-0.525909983|-0.523698331| 0.8238185634706201|1.8447459941860842| 0.8895499861991818|         0.053916161|-0.478409488|-0.505985449|       -0.379739927|0.8596232729306895| 0.7700327916850176|       -0.170370257| 0.1746881144547343|-0.884474618|         -0.72594475|1.9373630476634092|  1.823259776296592| 0.7739524788541774|      -0.107690273|-1.815057697|-1.396987954|       -0.312460046|1.6124978057991814| 1.4531946103476416|       -0.641704979| -0.13100451| -1.28512434|       -0.367818437|  1.282678902776366| 1.1832722460233605|      -0.013952538| -0.87834439|        -1.281883706|       -0.824858017|        0.573606185| 1.2770808147826727|0.45191125758961204|-0.299354043|-1.566279085|       -0.274251582|      -0.159047912| 0.8047769686743935|0.2084168537356223|       -0.286354455|    1735689602|[0.887286076,-0.0...|[0.49709915646348...|\n",
            "|01/01/2025 00:00:...| 0.9450313282577626| 1.174566206402339|        -0.43710474|-0.617916262|      -0.567243796|0.36465882290013313|        -0.539905165|        -0.02646467|  0.7751364631027378|-0.177844035|-1.732366245|       -0.305691692|       -0.112056162|0.45445084404737834| 1.2743622394314156|       -0.577484313|-1.686516865|-1.090563613| 0.1502641054551659|0.7539855285813324|  1.703250120266893| 0.44136452814694005| -0.32275285|-0.903456572|       -0.466220028|0.5501499827995295| 0.7963337249634345|       -0.046490499|       -1.133421368|-0.777979757|  0.4520661253035434|0.7398329912448095| 1.5837169766032506|  1.044460690761557|      -1.489958791|-0.738679649|-0.764595847| 0.5298457598998411|1.0711565316675926|0.24834481873531677|0.17081290407503885|-1.217344375|-1.744350731|        -0.01304799|        0.085135646| 0.5919524869235795|1.1889799830537424|-0.873114272|         -0.99380329|       -0.688900135| 1.1028555971611158| 1.4533617146774942| 1.0673920265868488|-1.031553826| -0.51052597|       -0.093706273| 1.184838049170846| 1.4869341090715682|0.3253957194614249| 0.1800494498077485|    1735689603|[0.94503132825776...|[0.51555629228506...|\n",
            "|01/01/2025 00:00:...| 0.9570318784482501|1.4198245207633757|0.34083109222520247|-0.224188113|      -0.630728932|       -0.336906745|        -0.357837653|  1.089235662906696|         0.600524235|-1.089729367|-0.295121555|       -1.076759734|        0.790257318| 1.2218579267504726|        0.083580685|       -0.664459779|-1.459197699|-1.270246025|        -0.26315363|1.1396284446448157| 1.4011249250476787|        -0.710198258| -0.02838282|-1.270816059| 0.8768067321443053|0.5806423712940785| 0.5289635409582363|0.25744170640182673|        -0.39363673|-0.828936573|        -0.098194897|0.9805964985469686|0.44040471674532233| 0.7118929392562539|      -0.938855603|-0.969840517|-1.528498985| 0.6842013696609908|1.0353671158060023| 0.3195069463086015|        -1.01340433|-0.486741808|-1.706827185|        0.024666542| 0.4213032852520662|0.17214292025286737|      -0.457509079|-0.738800675|        -1.095036596|0.13487848287091248| 0.5463258760901962|        0.728162881|       -0.889717849|-1.305457508|-1.395287893|       -1.287303685|0.7797319869637598| 1.6356162082531958|       0.402119884|0.22688153597134464|    1735689604|[0.95703187844825...|[0.51939203247390...|\n",
            "|01/01/2025 00:00:...|       -0.258102446|0.6358491750824797| 0.5059773638023992|-1.807790953|      -1.257680845|        -0.19327642|  0.5768570464717002| 1.4209176956955847|  0.5715437984519555| -0.59842143|-0.724614611|       -1.343614791| 0.7956417711212558| 1.0584656646594097| 0.6111928096077313| 0.5324310375916514|-0.556336329|-0.612114728|0.47464404798478943|0.8720282512342814|0.42097294590699774|  0.9009720094132461|-0.394055876|-1.204829698|       -0.765839037|0.8716407715350143| 1.7823093061085085| 0.3610739320844739|       -0.284833306|-0.792503222|        -0.056946922|0.5506507599803715| 1.7541999694571333|0.42342949254116513|0.6098870049655933|-1.320533775|  -0.3860626| 1.0139374999080597|0.5807708097455577|       -0.781387629|        -0.63310558|-0.242522738|-1.439050815|0.12365705290032626| 1.3547568173322708| 0.5947114541041156|       0.536900303|-0.112544801|        -1.846167233|       -0.758554292| 0.7053404429225867| 0.3939468009355396|        0.218182178|-0.924858043| -1.71673915|       -0.078801848|0.5341903896222407| 1.3945112282111822|0.6579998988242358|       -0.274079089|    1735689605|[-0.258102446,0.6...|[0.13099820976281...|\n",
            "|01/01/2025 00:00:...| 1.4021470587705887|0.9912907432220882| 1.7393715194403148|-0.114833511|      -1.303164445|        0.993714802|  0.5991606368352599| 1.7147260209115824|  1.3486110051128337|-0.210708252|-1.548145795|0.16949759644364437| 0.2573811660246592| 1.7309238180271371|       -0.179029105|       -0.709835669|-1.344823271|-0.563097435|0.22675794701954666|0.6370917311935385| 0.9187774872682846|        -0.064467628|-1.052467535|-0.575930055|       -0.212434653|0.9621701863341607| 1.9227941696068007|0.27777257253918064|       -1.065185017|-1.317313263|0.021955433940018032|0.5721519542351192|  1.040587185733417| 0.2304747285629405|      -0.555201489|-1.238476919|-0.751895553| 0.5139038294114934|0.9605790390524959| 0.5842444563591987|       -0.584199681|-0.290824941|-1.775154822| 0.9298558476985469| 0.7232261272005249| 0.5022441237265836|      -0.477597422| -0.91296561|        -0.788381615|       -0.066144834|  1.130782539946116| 1.4321381203831658|0.15115037237092313|-0.113513037|-0.884166476|        -1.47000295|1.0111965192180068|         0.09759323|       0.255136371|        0.723223873|    1735689606|[1.40214705877058...|[0.66166435821914...|\n",
            "|01/01/2025 00:00:...| 0.5378130389403717| 1.126817239307423|       -0.296971712|-1.081695274|      -1.019538435|       -0.930465331|  1.3911959845324091|0.44077784205886406|        -0.054808294|-0.930383503|-0.854530289|       -1.429988701|0.19630722304903958| 0.6979814435393336|0.27069578899083674|       -1.043297567|-0.237318115|-0.767607956|       -0.102277036|1.3024954029078624| 1.3554136428207655|  1.0798752194948065|-1.455863366|-0.917674881|       -0.709282797|0.6592386691375736| 1.8084167552863932|        0.595144095|0.10024776492116239|-0.748916413| 0.38061558207087276|1.1683440888455014|0.29909388522922775| 0.4704668381390576|      -0.141626517|-0.948668664|-0.071390997|0.44996483560449224|0.8888187035038905| 0.5649256084540368|       -0.222323695|-1.050918922|-1.128317919|0.46322978784880575|0.18698268667377493| 0.3851053554384919|      -0.810883867|-0.797351397|        -0.955670364|       -0.112732163|       -0.117779985|0.25548224006310216| 0.5881291777089587|-0.520318455|-0.393798039|       -0.528163715|0.4818446482253109| 1.2642029683219373|0.6057018220302867|       -0.709714795|    1735689607|[0.53781303894037...|[0.38539696349014...|\n",
            "|01/01/2025 00:00:...|0.13637185651863315|1.3308985822165547|        0.769995812|-0.959733025|      -0.767356135|       -0.203052974|  1.7841286591363867| 1.4260112026166787|        -0.105385726|-0.366309317|-0.434372224|       -0.713151721| 0.4034248391899115|0.20145727702960925| 0.9787328309571935|0.45119282765499186|-1.129838538|-0.543940891|0.39825254049881975|       0.886235636|  2.240628717380426|  0.8013125071980942|-0.281158959|-0.819996092|0.27590816716385946|      -0.710662918|0.22708075433953057| 0.4809957528605374|       -0.398719816|-0.171255626|        -1.057811276| 1.186979221827726| 1.5687196102157905|        0.716345592|      -0.060550149|-0.874703827|-0.162879249| 0.8636013670504659|1.6923373763738185|        0.620600303| 0.7925685075899888|-0.853501143|-0.363266591|       -0.153991391| 0.8585339581280423| 1.2912512365684656|       0.027141562| -0.40321362|        -1.637763505|       -0.185571412| 1.5391015968795543| 0.9651961087257036| 0.4022997233153063|-0.831857006|-1.105490658|0.27678721517514004|0.8297454086285048| 0.9933051769869945|       0.056142859|0.14083440210247733|    1735689608|[0.13637185651863...|[0.25708417345746...|\n",
            "|01/01/2025 00:00:...| 0.7373754682719977|       1.301262765|       -0.351042316|-1.076222138|      -1.239586972|        -0.27159309| 0.20512181546620267| 1.1676036923537538|        -0.120710527| -0.26997022|-0.308964545|       -0.225948845| 0.9068448048504155| 0.8776235429664204|0.36615386970722374|       -1.783061049|-0.066010815|-1.416281442|0.21976612916595512|0.6140802158757317| 0.5190251317776637|        -0.805516901|-1.312027038|-1.810790008|       -0.168922539|1.4115944462754477|0.22927168769672657| 0.3365060131532646|       -0.189000647|-1.730907326|        -0.190270333|1.0395922775717845| 1.2752855760129331|        0.061674654|      -0.696870535|-0.755511995|-0.600212652|       -0.042562455|0.5324418500401099| 0.5629320727609113|       -0.568295251|-1.381089698|-0.355705921|0.38164099282690134| 0.4072914321356566| 0.7588596806173171|0.1391541600816369|-0.873615339|0.026805696675446522|       -0.163692705|0.33016130004673294| 1.9641090153001186|       -0.040418099|-0.932667515|-1.152184662|       -0.416310006|       0.039104052|  1.374113926264268|0.7738396398945568|        0.006651563|    1735689609|[0.73737546827199...|[0.44918317480700...|\n",
            "+--------------------+-------------------+------------------+-------------------+------------+------------------+-------------------+--------------------+-------------------+--------------------+------------+------------+-------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+-------------------+------------------+-------------------+--------------------+------------+------------+-------------------+------------------+-------------------+-------------------+-------------------+------------+--------------------+------------------+-------------------+-------------------+------------------+------------+------------+-------------------+------------------+-------------------+-------------------+------------+------------+-------------------+-------------------+-------------------+------------------+------------+--------------------+-------------------+-------------------+-------------------+-------------------+------------+------------+-------------------+------------------+-------------------+------------------+-------------------+--------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import ArrayType, DoubleType\n",
        "import pandas as pd\n",
        "\n",
        "df_pandas = df_scaled.select(\"features\").toPandas()\n",
        "\n",
        "features_np = np.array([row.toArray() for row in df_pandas['features']])\n",
        "\n",
        "split_idx = int(0.8 * len(features_np))\n",
        "train_data = features_np[:split_idx]\n",
        "val_data = features_np[split_idx:]\n",
        "\n",
        "param_list = [\n",
        "     {\"epochs\": 20, \"batch_size\": 32, \"learning_rate\": 0.001},\n",
        "     {\"epochs\": 20, \"batch_size\": 64, \"learning_rate\": 0.001},\n",
        "     {\"epochs\": 20, \"batch_size\": 128, \"learning_rate\": 0.001},\n",
        "     {\"epochs\": 20, \"batch_size\": 32, \"learning_rate\": 0.0005},\n",
        "     {\"epochs\": 20, \"batch_size\": 64, \"learning_rate\": 0.0005}\n",
        " ]\n",
        "\n",
        "best_loss = float(\"inf\")\n",
        "best_params = None\n",
        "\n",
        "for params in param_list:\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "    input_layer = keras.Input(shape=(60,))\n",
        "    encoded = layers.Dense(40, activation=\"relu\")(input_layer)\n",
        "    encoded = layers.Dense(20, activation=\"relu\")(encoded)\n",
        "    encoded = layers.Dense(10, activation=\"relu\")(encoded)\n",
        "    decoded = layers.Dense(20, activation=\"relu\")(encoded)\n",
        "    decoded = layers.Dense(40, activation=\"relu\")(decoded)\n",
        "    output_layer = layers.Dense(60, activation=\"sigmoid\")(decoded)\n",
        "\n",
        "    autoencoder = keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=params[\"learning_rate\"])\n",
        "    autoencoder.compile(optimizer=optimizer, loss=\"mse\")\n",
        "\n",
        "    history = autoencoder.fit(\n",
        "        train_data, train_data,\n",
        "        epochs=params[\"epochs\"],\n",
        "        batch_size=params[\"batch_size\"],\n",
        "        shuffle=True,\n",
        "        validation_data=(val_data, val_data),\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    val_loss = min(history.history[\"val_loss\"])\n",
        "    print(f\"Params: {params}, Min Val Loss: {val_loss}\")\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        best_params = params\n",
        "\n",
        "print(f\"\\nBest Params: {best_params} with Loss: {best_loss}\")\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "input_layer = keras.Input(shape=(60,))\n",
        "encoded = layers.Dense(40, activation=\"relu\")(input_layer)\n",
        "encoded = layers.Dense(20, activation=\"relu\")(encoded)\n",
        "encoded = layers.Dense(10, activation=\"relu\")(encoded)\n",
        "decoded = layers.Dense(20, activation=\"relu\")(encoded)\n",
        "decoded = layers.Dense(40, activation=\"relu\")(decoded)\n",
        "output_layer = layers.Dense(60, activation=\"sigmoid\")(decoded)\n",
        "\n",
        "autoencoder = keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "optimizer = keras.optimizers.Adam(learning_rate=best_params[\"learning_rate\"])\n",
        "autoencoder.compile(optimizer=optimizer, loss=\"mse\")\n",
        "\n",
        "autoencoder.fit(\n",
        "    train_data, train_data,\n",
        "    epochs=best_params[\"epochs\"],\n",
        "    batch_size=best_params[\"batch_size\"],\n",
        "    shuffle=True,\n",
        "    validation_data=(val_data, val_data),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "autoencoder.save(\"/content/best_autoencoder.keras\")\n",
        "print(\"Model saved at /content/best_autoencoder.keras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9sGLNDGBija",
        "outputId": "dcc09575-aea8-47f1-8889-5fa01688abe2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Params: {'epochs': 5, 'batch_size': 32, 'learning_rate': 0.001}, Min Val Loss: 0.023620935156941414\n",
            "Params: {'epochs': 5, 'batch_size': 64, 'learning_rate': 0.001}, Min Val Loss: 0.02386954054236412\n",
            "Params: {'epochs': 5, 'batch_size': 32, 'learning_rate': 0.0005}, Min Val Loss: 0.023577477782964706\n",
            "\n",
            "Best Params: {'epochs': 5, 'batch_size': 32, 'learning_rate': 0.0005} with Loss: 0.023577477782964706\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0258 - val_loss: 0.0254\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0255 - val_loss: 0.0248\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0249 - val_loss: 0.0243\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0244 - val_loss: 0.0241\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0243 - val_loss: 0.0240\n",
            "Model saved at /content/best_autoencoder.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "autoencoder.save(\"/content/drive/My Drive/best_autoencoder.keras\")\n",
        "print(\"Model saved to Drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MspC4d8vUUtS",
        "outputId": "203151e7-7410-4298-c276-78c8301fa6a2"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Model saved to Drive\n"
          ]
        }
      ]
    }
  ]
}