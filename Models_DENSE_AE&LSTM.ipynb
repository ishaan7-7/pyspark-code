{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d16dc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Saved: C:\\Users\\Ishaan Tiwari\\Desktop\\Kafka\\artifacts\\scaler_prod.joblib\n",
      "Saved: C:\\Users\\Ishaan Tiwari\\Desktop\\Kafka\\artifacts\\features.json\n",
      "Saved: C:\\Users\\Ishaan Tiwari\\Desktop\\Kafka\\artifacts\\seq_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Artifacts saved in 'artifacts/':\n",
      " - C:\\Users\\Ishaan Tiwari\\Desktop\\Kafka\\artifacts\\scaler_small.joblib\n",
      " - C:\\Users\\Ishaan Tiwari\\Desktop\\Kafka\\artifacts\\scaler_prod.joblib\n",
      " - C:\\Users\\Ishaan Tiwari\\Desktop\\Kafka\\artifacts\\features.json\n",
      " - C:\\Users\\Ishaan Tiwari\\Desktop\\Kafka\\artifacts\\seq_config.json\n",
      " - C:\\Users\\Ishaan Tiwari\\Desktop\\Kafka\\artifacts\\param_sets.json\n",
      " - C:\\Users\\Ishaan Tiwari\\Desktop\\Kafka\\artifacts\\training_report.json\n",
      " - C:\\Users\\Ishaan Tiwari\\Desktop\\Kafka\\artifacts\\artifacts_index.json\n",
      "\n",
      "Model variants saved under 'Models/':\n",
      " - artifact_1: Models/artifact_1\n",
      " - artifact_2: Models/artifact_2\n",
      " - artifact_3: Models/artifact_3\n",
      " - artifact_4: Models/artifact_4\n",
      " - artifact_5: Models/artifact_5\n"
     ]
    }
   ],
   "source": [
    "import os, json, random\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "\n",
    "SMALL_CSV = \"Book1.csv\"   \n",
    "BIG_CSV   = \"Book1.csv\"  \n",
    "\n",
    "ARTIFACTS_DIR = Path(\"artifacts\"); ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODELS_DIR = Path(\"Models\"); MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FEATURES = [f\"signal_{i}\" for i in range(1, 61)]\n",
    "TIMESTAMP_COL = \"Timestamp\"  \n",
    "\n",
    "SEQ_LEN = 30\n",
    "STRIDE  = 1\n",
    "\n",
    "\n",
    "PARAM_SETS = [\n",
    "    {\n",
    "        \"id\": \"artifact_1\",\n",
    "        \"dense\": {\"lr\": 1e-3, \"batch\": 512, \"epochs\": 40, \"patience\": 5, \"weight_decay\": 0.0},\n",
    "        \"lstm\":  {\"lr\": 1e-3, \"batch\": 128, \"epochs\": 40, \"patience\": 5, \"hidden\": 64, \"latent\": 16, \"layers\": 1},\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"artifact_2\",\n",
    "        \"dense\": {\"lr\": 5e-4, \"batch\": 512, \"epochs\": 50, \"patience\": 6, \"weight_decay\": 1e-5},\n",
    "        \"lstm\":  {\"lr\": 5e-4, \"batch\": 128, \"epochs\": 50, \"patience\": 6, \"hidden\": 96, \"latent\": 24, \"layers\": 1},\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"artifact_3\",\n",
    "        \"dense\": {\"lr\": 1e-3, \"batch\": 1024, \"epochs\": 35, \"patience\": 5, \"weight_decay\": 1e-6},\n",
    "        \"lstm\":  {\"lr\": 1e-3, \"batch\": 256, \"epochs\": 35, \"patience\": 5, \"hidden\": 80, \"latent\": 20, \"layers\": 1},\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"artifact_4\",\n",
    "        \"dense\": {\"lr\": 2e-3, \"batch\": 512, \"epochs\": 30, \"patience\": 4, \"weight_decay\": 0.0},\n",
    "        \"lstm\":  {\"lr\": 2e-3, \"batch\": 128, \"epochs\": 30, \"patience\": 4, \"hidden\": 64, \"latent\": 16, \"layers\": 2},\n",
    "    },\n",
    "    \n",
    "    {\n",
    "         \"id\": \"artifact_5\",\n",
    "         \"dense\": {\"lr\": 7e-4, \"batch\": 512, \"epochs\": 45, \"patience\": 5, \"weight_decay\": 5e-6},\n",
    "         \"lstm\":  {\"lr\": 7e-4, \"batch\": 128, \"epochs\": 45, \"patience\": 5, \"hidden\": 72, \"latent\": 18, \"layers\": 1},\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def load_signals_csv(path, features=FEATURES, timestamp_col=TIMESTAMP_COL):\n",
    "    cols_in_file = pd.read_csv(path, nrows=0).columns.tolist()\n",
    "    usecols = [c for c in features if c in cols_in_file] + ([timestamp_col] if timestamp_col in cols_in_file else [])\n",
    "    df = pd.read_csv(path, usecols=usecols)\n",
    "    \n",
    "    for f in features:\n",
    "        if f not in df.columns:\n",
    "            df[f] = 0.0\n",
    "    X = df[features].astype(\"float32\").values\n",
    "    return X\n",
    "\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X):\n",
    "        self.X = np.asarray(X, dtype=np.float32)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, idx): return torch.from_numpy(self.X[idx])\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, X_scaled, seq_len=30, stride=1):\n",
    "        self.seq_len = seq_len; self.stride = stride\n",
    "        X = np.asarray(X_scaled, dtype=np.float32)\n",
    "        n = len(X)\n",
    "        if n < seq_len:\n",
    "            self.X_seq = np.empty((0, seq_len, X.shape[1]), dtype=np.float32)\n",
    "        else:\n",
    "            num = (n - seq_len) // stride + 1\n",
    "            self.X_seq = np.stack([X[i*stride:i*stride+seq_len] for i in range(num)], axis=0)\n",
    "    def __len__(self): return len(self.X_seq)\n",
    "    def __getitem__(self, idx): return torch.from_numpy(self.X_seq[idx])\n",
    "\n",
    "class DenseAE(nn.Module):\n",
    "    def __init__(self, in_dim=60):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_dim, 40), nn.ReLU(),\n",
    "            nn.Linear(40, 20), nn.ReLU(),\n",
    "            nn.Linear(20, 10), nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(10, 20), nn.ReLU(),\n",
    "            nn.Linear(20, 40), nn.ReLU(),\n",
    "            nn.Linear(40, in_dim),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "\n",
    "class LSTMAE(nn.Module):\n",
    "    def __init__(self, input_dim=60, hidden_dim=64, latent_dim=16, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.encoder = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.to_latent = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "        self.from_latent = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.decoder = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_dim, input_dim)\n",
    "\n",
    "    def forward(self, x):  \n",
    "        enc_out, _ = self.encoder(x)          \n",
    "        h_last = enc_out[:, -1, :]            \n",
    "        z = self.to_latent(h_last)            \n",
    "\n",
    "        B = x.size(0)\n",
    "        base = self.from_latent(z)            \n",
    "        h0 = base.unsqueeze(0).repeat(self.num_layers, 1, 1)  \n",
    "        c0 = torch.zeros(self.num_layers, B, self.hidden_dim, device=x.device, dtype=x.dtype)\n",
    "\n",
    "        dec_out, _ = self.decoder(x, (h0, c0))  \n",
    "        y = self.out(dec_out)                   \n",
    "        return y\n",
    "\n",
    "\n",
    "def make_loader(ds, batch_size=256, shuffle_flag=True):\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle_flag,\n",
    "                      drop_last=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "def train_one_dense(params: Dict[str, Any], Xtr, Xval):\n",
    "    model = DenseAE(in_dim=60).to(DEVICE)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=params[\"lr\"],\n",
    "                            weight_decay=params.get(\"weight_decay\", 0.0))\n",
    "    crit = nn.MSELoss()\n",
    "    tr_loader = make_loader(TabularDataset(Xtr), batch_size=params[\"batch\"], shuffle_flag=True)\n",
    "    va_loader = make_loader(TabularDataset(Xval), batch_size=params[\"batch\"], shuffle_flag=False)\n",
    "    patience = int(params.get(\"patience\", 5))\n",
    "    epochs = int(params.get(\"epochs\", 50))\n",
    "    best_val = float(\"inf\"); best_state = None; no_imp = 0\n",
    "    hist = {\"train\": [], \"val\": []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train(); tr_sum=0.0; n_tr=0\n",
    "        for xb in tr_loader:\n",
    "            xb = xb.to(DEVICE)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            recon = model(xb)\n",
    "            loss = crit(recon, xb)\n",
    "            loss.backward(); opt.step()\n",
    "            tr_sum += loss.item()*xb.size(0); n_tr += xb.size(0)\n",
    "        tr_loss = tr_sum / max(1, n_tr)\n",
    "        model.eval(); va_sum=0.0; n_va=0\n",
    "        with torch.no_grad():\n",
    "            for xb in va_loader:\n",
    "                xb = xb.to(DEVICE)\n",
    "                recon = model(xb); loss = crit(recon, xb)\n",
    "                va_sum += loss.item()*xb.size(0); n_va += xb.size(0)\n",
    "        va_loss = va_sum / max(1, n_va)\n",
    "        hist[\"train\"].append(float(tr_loss)); hist[\"val\"].append(float(va_loss))\n",
    "        if va_loss < best_val - 1e-8:\n",
    "            best_val = va_loss\n",
    "            best_state = {k: v.detach().cpu().clone() for k,v in model.state_dict().items()}\n",
    "            no_imp = 0\n",
    "        else:\n",
    "            no_imp += 1\n",
    "            if no_imp >= patience: break\n",
    "    if best_state is not None: model.load_state_dict(best_state)\n",
    "    return model, float(best_val), hist\n",
    "\n",
    "def train_one_lstm(params: Dict[str, Any], Xtr, Xval, seq_len=30, stride=1):\n",
    "    model = LSTMAE(input_dim=60,\n",
    "                   hidden_dim=int(params.get(\"hidden\",64)),\n",
    "                   latent_dim=int(params.get(\"latent\",16)),\n",
    "                   num_layers=int(params.get(\"layers\",1))).to(DEVICE)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=params[\"lr\"])\n",
    "    crit = nn.MSELoss()\n",
    "    tr_loader = make_loader(SequenceDataset(Xtr, seq_len=seq_len, stride=stride),\n",
    "                            batch_size=params[\"batch\"], shuffle_flag=True)\n",
    "    va_seq_ds = SequenceDataset(Xval, seq_len=seq_len, stride=stride)\n",
    "    va_loader = make_loader(va_seq_ds, batch_size=params[\"batch\"], shuffle_flag=False)\n",
    "    patience = int(params.get(\"patience\", 5))\n",
    "    epochs = int(params.get(\"epochs\", 50))\n",
    "    best_val = float(\"inf\"); best_state = None; no_imp = 0\n",
    "    hist = {\"train\": [], \"val\": []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train(); tr_sum=0.0; n_tr=0\n",
    "        for xb in tr_loader:\n",
    "            xb = xb.to(DEVICE)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            recon = model(xb)\n",
    "            loss = crit(recon, xb)\n",
    "            loss.backward(); opt.step()\n",
    "            tr_sum += loss.item()*xb.size(0); n_tr += xb.size(0)\n",
    "        tr_loss = tr_sum / max(1, n_tr)\n",
    "        model.eval(); va_sum=0.0; n_va=0\n",
    "        with torch.no_grad():\n",
    "            for xb in va_loader:\n",
    "                xb = xb.to(DEVICE)\n",
    "                recon = model(xb); loss = crit(recon, xb)\n",
    "                va_sum += loss.item()*xb.size(0); n_va += xb.size(0)\n",
    "        va_loss = va_sum / max(1, n_va)\n",
    "        hist[\"train\"].append(float(tr_loss)); hist[\"val\"].append(float(va_loss))\n",
    "        if va_loss < best_val - 1e-8:\n",
    "            best_val = va_loss\n",
    "            best_state = {k: v.detach().cpu().clone() for k,v in model.state_dict().items()}\n",
    "            no_imp = 0\n",
    "        else:\n",
    "            no_imp += 1\n",
    "            if no_imp >= patience: break\n",
    "    if best_state is not None: model.load_state_dict(best_state)\n",
    "    return model, float(best_val), hist\n",
    "\n",
    "def dense_val_errors(model: nn.Module, Xval):\n",
    "    \"\"\"Return per-row MSE errors on validation (for thresholds).\"\"\"\n",
    "    model.eval(); crit = nn.MSELoss(reduction=\"none\")\n",
    "    loader = make_loader(TabularDataset(Xval), batch_size=1024, shuffle_flag=False)\n",
    "    errs = []\n",
    "    with torch.no_grad():\n",
    "        for xb in loader:\n",
    "            xb = xb.to(DEVICE)\n",
    "            recon = model(xb)\n",
    "            se = (recon - xb)**2\n",
    "            row_mse = se.mean(dim=1)  # (B,)\n",
    "            errs.append(row_mse.detach().cpu().numpy())\n",
    "    if errs:\n",
    "        e = np.concatenate(errs, axis=0)\n",
    "    else:\n",
    "        e = np.zeros((0,), dtype=np.float32)\n",
    "    return e\n",
    "\n",
    "def lstm_val_errors(model: nn.Module, Xval, seq_len=30, stride=1):\n",
    "    \"\"\"Return per-window MSE errors on validation (averaged over T and F).\"\"\"\n",
    "    model.eval(); crit = nn.MSELoss(reduction=\"none\")\n",
    "    ds = SequenceDataset(Xval, seq_len=seq_len, stride=stride)\n",
    "    loader = make_loader(ds, batch_size=256, shuffle_flag=False)\n",
    "    errs = []\n",
    "    with torch.no_grad():\n",
    "        for xb in loader:\n",
    "            xb = xb.to(DEVICE)\n",
    "            recon = model(xb)\n",
    "            se = (recon - xb)**2\n",
    "            win_mse = se.mean(dim=(1,2))  \n",
    "            errs.append(win_mse.detach().cpu().numpy())\n",
    "    if errs:\n",
    "        e = np.concatenate(errs, axis=0)\n",
    "    else:\n",
    "        e = np.zeros((0,), dtype=np.float32)\n",
    "    return e\n",
    "\n",
    "def percentiles(arr, ps=(90,95,99)):\n",
    "    if arr.size == 0:\n",
    "        return {f\"p{p}\": None for p in ps}\n",
    "    return {f\"p{p}\": float(np.percentile(arr, p)) for p in ps}\n",
    "\n",
    "\n",
    "X_small = load_signals_csv(SMALL_CSV, FEATURES, TIMESTAMP_COL)\n",
    "X_s_tr, X_s_va = train_test_split(X_small, test_size=0.2, random_state=SEED, shuffle=True)\n",
    "\n",
    "scaler_small = MinMaxScaler()\n",
    "Xs_tr = scaler_small.fit_transform(X_s_tr)\n",
    "Xs_va = scaler_small.transform(X_s_va)\n",
    "\n",
    "\n",
    "joblib.dump(scaler_small, ARTIFACTS_DIR/\"scaler_small.joblib\")\n",
    "\n",
    "\n",
    "X_big = load_signals_csv(BIG_CSV, FEATURES, TIMESTAMP_COL)\n",
    "Xb_tr, Xb_val = train_test_split(X_big, test_size=0.2, random_state=SEED, shuffle=True)\n",
    "\n",
    "scaler_prod = MinMaxScaler()\n",
    "Xb_tr_s = scaler_prod.fit_transform(Xb_tr)\n",
    "Xb_val_s = scaler_prod.transform(Xb_val)\n",
    "\n",
    "joblib.dump(scaler_prod, ARTIFACTS_DIR/\"scaler_prod.joblib\")\n",
    "with open(ARTIFACTS_DIR/\"features.json\",\"w\") as f:\n",
    "    json.dump({\"features\": FEATURES, \"timestamp_col\": TIMESTAMP_COL}, f, indent=2)\n",
    "with open(ARTIFACTS_DIR/\"seq_config.json\",\"w\") as f:\n",
    "    json.dump({\"seq_len\": int(SEQ_LEN), \"stride\": int(STRIDE)}, f, indent=2)\n",
    "\n",
    "print(\"Saved:\", (ARTIFACTS_DIR/\"scaler_prod.joblib\").resolve())\n",
    "print(\"Saved:\", (ARTIFACTS_DIR/\"features.json\").resolve())\n",
    "print(\"Saved:\", (ARTIFACTS_DIR/\"seq_config.json\").resolve())\n",
    "\n",
    "\n",
    "training_report = {}\n",
    "artifacts_index = []\n",
    "\n",
    "json.dump(PARAM_SETS, open(ARTIFACTS_DIR/\"param_sets.json\",\"w\"), indent=2)\n",
    "\n",
    "for i, cfg in enumerate(PARAM_SETS, start=1):\n",
    "    art_id = cfg.get(\"id\", f\"artifact_{i}\")\n",
    "    out_dir = MODELS_DIR / art_id\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    \n",
    "    dense_model, dense_val, dense_hist = train_one_dense(cfg[\"dense\"], Xb_tr_s, Xb_val_s)\n",
    "    torch.save(dense_model.state_dict(), out_dir/\"dense_ae.pt\")\n",
    "\n",
    "    \n",
    "    d_errs = dense_val_errors(dense_model, Xb_val_s)\n",
    "    d_thresh = percentiles(d_errs, ps=(90,95,99))\n",
    "\n",
    "   \n",
    "    lstm_model, lstm_val, lstm_hist = train_one_lstm(cfg[\"lstm\"], Xb_tr_s, Xb_val_s,\n",
    "                                                     seq_len=SEQ_LEN, stride=STRIDE)\n",
    "    torch.save(lstm_model.state_dict(), out_dir/\"lstm_ae.pt\")\n",
    "\n",
    "    l_errs = lstm_val_errors(lstm_model, Xb_val_s, seq_len=SEQ_LEN, stride=STRIDE)\n",
    "    l_thresh = percentiles(l_errs, ps=(90,95,99))\n",
    "\n",
    "   \n",
    "    manifest = {\n",
    "        \"id\": art_id,\n",
    "        \"dense_params\": cfg[\"dense\"],\n",
    "        \"lstm_params\": cfg[\"lstm\"],\n",
    "        \"input_dim\": 60,\n",
    "        \"seq_len\": int(SEQ_LEN),\n",
    "        \"stride\": int(STRIDE),\n",
    "        \"val_losses\": {\"dense\": float(dense_val), \"lstm\": float(lstm_val)},\n",
    "        \"files\": {\n",
    "            \"dense_ae\": str((out_dir/\"dense_ae.pt\").as_posix()),\n",
    "            \"lstm_ae\": str((out_dir/\"lstm_ae.pt\").as_posix()),\n",
    "        }\n",
    "    }\n",
    "    json.dump(manifest, open(out_dir/\"manifest.json\",\"w\"), indent=2)\n",
    "\n",
    "    thresholds = {\n",
    "        \"dense_row_mse\": d_thresh, \n",
    "        \"lstm_win_mse\":  l_thresh,  \n",
    "        \"notes\": \"Thresholds are percentiles of validation reconstruction MSE. Use p95/p99 for anomaly flags; tune per stream.\"\n",
    "    }\n",
    "    json.dump(thresholds, open(out_dir/\"thresholds.json\",\"w\"), indent=2)\n",
    "\n",
    "    metrics = {\n",
    "        \"dense_loss_history\": dense_hist,\n",
    "        \"lstm_loss_history\": lstm_hist,\n",
    "        \"dense_val_errors_preview\": [float(x) for x in d_errs[:1000]],  \n",
    "        \"lstm_val_errors_preview\":  [float(x) for x in l_errs[:1000]],\n",
    "    }\n",
    "    json.dump(metrics, open(out_dir/\"metrics.json\",\"w\"), indent=2)\n",
    "\n",
    "    training_report[art_id] = {\n",
    "        \"dense\": {\"best_val\": float(dense_val)},\n",
    "        \"lstm\":  {\"best_val\": float(lstm_val)},\n",
    "        \"thresholds\": {\"dense\": d_thresh, \"lstm\": l_thresh},\n",
    "    }\n",
    "    artifacts_index.append({\n",
    "        \"id\": art_id,\n",
    "        \"path\": str(out_dir.as_posix()),\n",
    "        \"dense_val\": float(dense_val),\n",
    "        \"lstm_val\": float(lstm_val),\n",
    "        \"dense_pt\": str((out_dir/\"dense_ae.pt\").as_posix()),\n",
    "        \"lstm_pt\": str((out_dir/\"lstm_ae.pt\").as_posix()),\n",
    "    })\n",
    "\n",
    "\n",
    "json.dump(training_report, open(ARTIFACTS_DIR/\"training_report.json\",\"w\"), indent=2)\n",
    "json.dump(artifacts_index, open(ARTIFACTS_DIR/\"artifacts_index.json\",\"w\"), indent=2)\n",
    "\n",
    "\n",
    "print(\"\\nArtifacts saved in 'artifacts/':\")\n",
    "for p in [\n",
    "    ARTIFACTS_DIR/\"scaler_small.joblib\",\n",
    "    ARTIFACTS_DIR/\"scaler_prod.joblib\",\n",
    "    ARTIFACTS_DIR/\"features.json\",\n",
    "    ARTIFACTS_DIR/\"seq_config.json\",\n",
    "    ARTIFACTS_DIR/\"param_sets.json\",\n",
    "    ARTIFACTS_DIR/\"training_report.json\",\n",
    "    ARTIFACTS_DIR/\"artifacts_index.json\",\n",
    "]:\n",
    "    print(\" -\", p.resolve())\n",
    "\n",
    "print(\"\\nModel variants saved under 'Models/':\")\n",
    "for item in artifacts_index:\n",
    "    print(f\" - {item['id']}: {item['path']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e77f29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
