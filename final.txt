import matplotlib.pyplot as plt
import pandas as pd

# Step 1: Get list of all columns
columns = df.columns
timestamp_col = "timestamp"
signal_cols = [col for col in columns if col.startswith("signal_")]

# Step 2: Cache DataFrame for better performance
df.cache()

# Step 3: Loop through each signal column
for signal in signal_cols:
    print(f"Plotting: {signal}")
    
    # Step 3a: Select timestamp and this signal column
    temp_df = df.select(timestamp_col, signal)
    
    # Step 3b: Limit to a reasonable number of points for plotting (e.g., 5000)
    temp_pdf = temp_df.limit(5000).toPandas()
    
    # Step 3c: Plot using matplotlib
    plt.figure(figsize=(10, 5))
    plt.scatter(temp_pdf[timestamp_col], temp_pdf[signal], s=5, c='blue')
    plt.xlabel("Timestamp")
    plt.ylabel(signal)
    plt.title(f"Scatter Plot of {signal}")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()



import matplotlib.pyplot as plt
import pandas as pd
from pyspark.sql import functions as F

# Step 1: Identify columns
timestamp_col = "timestamp"
signal_cols = [col for col in df.columns if col.startswith("signal_")]

# Step 2: Sample every 100th row (~6000 rows)
sampled_df = df.withColumn("row_id", F.monotonically_increasing_id()).filter("row_id % 100 == 0").drop("row_id")
sampled_df.cache()

# Step 3: Convert entire sampled DF to Pandas ONCE
pdf = sampled_df.select([timestamp_col] + signal_cols).toPandas()

# Step 4: Convert timestamp column to datetime (for better plotting)
pdf[timestamp_col] = pd.to_datetime(pdf[timestamp_col], format="%m/%d/%Y %H:%M:%S:%f")

# Step 5: Plot each signal
for signal in signal_cols:
    print(f"Plotting: {signal}")
    plt.figure(figsize=(10, 5))
    plt.scatter(pdf[timestamp_col], pdf[signal], s=5, c='blue')
    plt.xlabel("Timestamp")
    plt.ylabel(signal)
    plt.title(f"Scatter Plot of {signal}")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()



import matplotlib.pyplot as plt
import pandas as pd
from pyspark.sql import functions as F

# Step 1: Keep only 10 signals and timestamp
selected_signals = ["timestamp"] + [f"signal_{i}" for i in range(1, 11)]
df_10 = df.select(*selected_signals)

# Step 2: Filter anomaly data to match 10 selected signals
selected_signal_names = [f"signal_{i}" for i in range(1, 11)]
anomaly_df_10 = anomaly_df.filter(F.col("signal").isin(selected_signal_names))

# Step 3: Convert both DataFrames to Pandas
pdf = df_10.toPandas()
pdf["timestamp"] = pd.to_datetime(pdf["timestamp"], format="%m/%d/%Y %H:%M:%S:%f")

anomaly_pdf = anomaly_df_10.toPandas()
anomaly_pdf["start_timestamp"] = pd.to_datetime(anomaly_pdf["start_timestamp"], format="%m/%d/%Y %H:%M:%S:%f")
anomaly_pdf["end_timestamp"] = pd.to_datetime(anomaly_pdf["end_timestamp"], format="%m/%d/%Y %H:%M:%S:%f")

# Step 4: Group anomalies by signal
anomaly_dict = {}
for _, row in anomaly_pdf.iterrows():
    signal = row["signal"]
    if signal not in anomaly_dict:
        anomaly_dict[signal] = []
    anomaly_dict[signal].append((row["start_timestamp"], row["end_timestamp"], row["anomaly_type"]))

# Step 5: Plot each signal with full 600K points
for signal in [col for col in pdf.columns if col.startswith("signal_")]:
    print(f"Rendering full plot for: {signal}")
    plt.figure(figsize=(12, 5))

    # Full scatter of signal points
    plt.scatter(pdf["timestamp"], pdf[signal], s=1, c='blue', label="Signal")

    # Highlight anomaly windows
    if signal in anomaly_dict:
        for (start_ts, end_ts, anomaly_type) in anomaly_dict[signal]:
            # Red vertical lines at start/end
            plt.axvline(x=start_ts, color='red', linestyle='--', linewidth=1.0)
            plt.axvline(x=end_ts, color='red', linestyle='--', linewidth=1.0)

            # Yellow line within the window
            mask = (pdf["timestamp"] >= start_ts) & (pdf["timestamp"] <= end_ts)
            if mask.sum() > 1:
                plt.plot(pdf.loc[mask, "timestamp"], pdf.loc[mask, signal], color='yellow', linewidth=1.5, label=f"Anomaly ({anomaly_type})")

    plt.xlabel("Timestamp")
    plt.ylabel(signal)
    plt.title(f"Full Signal Plot with Anomalies: {signal}")
    plt.xticks(rotation=45)
    plt.legend(loc="upper right")
    plt.tight_layout()
    plt.show()




import pandas as pd
import matplotlib.pyplot as plt

# Ensure your dataframes are ready
df = df.toPandas()
anomalydf = pd.read_csv("/dbfs/mnt/data/anomaly_windows_complex.csv")

# Convert timestamps
df["timestamp"] = pd.to_datetime(df["timestamp"], format="%m/%d/%Y %H:%M:%S:%f")
anomalydf["start_timestamp"] = pd.to_datetime(anomalydf["start_timestamp"], format="%m/%d/%Y %H:%M:%S:%f")
anomalydf["end_timestamp"] = pd.to_datetime(anomalydf["end_timestamp"], format="%m/%d/%Y %H:%M:%S:%f")

# Limit to 10 signals
signals = [f"signal_{i}" for i in range(1, 11)]

for signal in signals:
    plt.figure(figsize=(10, 5))

    # Sort main df by timestamp
    signal_df = df[["timestamp", signal]].sort_values("timestamp")

    # Merge all anomaly windows for this signal
    anomaly_windows = anomalydf[anomalydf["signal"] == signal].sort_values("start_timestamp")

    # Prepare index for slicing
    timestamps = signal_df["timestamp"].values
    values = signal_df[signal].values

    # Initialize pointers
    last_idx = 0

    for _, row in anomaly_windows.iterrows():
        start = row["start_timestamp"]
        end = row["end_timestamp"]

        # Find indexes where window applies
        start_idx = signal_df[signal_df["timestamp"] >= start].index.min()
        end_idx = signal_df[signal_df["timestamp"] <= end].index.max()

        # Plot normal region before window
        if start_idx > last_idx:
            plt.plot(timestamps[last_idx:start_idx+1], values[last_idx:start_idx+1], color="blue", linewidth=1.2)

        # Plot anomaly window in yellow
        plt.plot(timestamps[start_idx:end_idx+1], values[start_idx:end_idx+1], color="yellow", linewidth=2)

        # Red lines to mark window
        plt.axvline(x=start, color="red", linestyle="--", linewidth=1)
        plt.axvline(x=end, color="red", linestyle="--", linewidth=1)

        # Update last_idx
        last_idx = end_idx + 1

    # Plot any remaining normal region after last anomaly
    if last_idx < len(timestamps) - 1:
        plt.plot(timestamps[last_idx:], values[last_idx:], color="blue", linewidth=1.2)

    # Final decorations
    plt.title(f"Signal: {signal}")
    plt.xlabel("Timestamp")
    plt.ylabel("Value")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()



import pandas as pd
import matplotlib.pyplot as plt

# Convert Spark DF to Pandas if not already done
df = df.toPandas()

# Load anomaly windows
anomalydf = pd.read_csv("/dbfs/mnt/data/anomaly_windows_complex.csv")

# Convert timestamps
df["timestamp"] = pd.to_datetime(df["timestamp"], format="%m/%d/%Y %H:%M:%S:%f")
anomalydf["start_timestamp"] = pd.to_datetime(anomalydf["start_timestamp"], format="%m/%d/%Y %H:%M:%S:%f")
anomalydf["end_timestamp"] = pd.to_datetime(anomalydf["end_timestamp"], format="%m/%d/%Y %H:%M:%S:%f")

# Extract signal columns dynamically
signals = [col for col in df.columns if col.startswith("signal_")]

# Sort main df
df = df.sort_values("timestamp").reset_index(drop=True)

# Plot for each signal
for signal in signals:
    plt.figure(figsize=(10, 5))

    # Get time and values
    timestamps = df["timestamp"].values
    values = df[signal].values

    # Filter anomaly windows for this signal
    windows = anomalydf[anomalydf["signal"] == signal].sort_values("start_timestamp")

    # Initialize pointer for where last segment ended
    last_idx = 0

    for _, row in windows.iterrows():
        start_ts = row["start_timestamp"]
        end_ts = row["end_timestamp"]

        # Get integer index positions
        start_mask = df["timestamp"] >= start_ts
        end_mask = df["timestamp"] <= end_ts

        if start_mask.any() and end_mask.any():
            start_idx = start_mask.idxmax()
            end_idx = end_mask[::-1].idxmax()  # reverse mask to find last True

            # Plot normal segment before anomaly
            if start_idx > last_idx:
                plt.plot(timestamps[last_idx:start_idx+1], values[last_idx:start_idx+1], color="blue", linewidth=1.2)

            # Plot anomaly segment
            plt.plot(timestamps[start_idx:end_idx+1], values[start_idx:end_idx+1], color="yellow", linewidth=2)

            # Red vertical lines
            plt.axvline(x=start_ts, color="red", linestyle="--", linewidth=1)
            plt.axvline(x=end_ts, color="red", linestyle="--", linewidth=1)

            last_idx = end_idx + 1

    # Plot remaining normal data after last anomaly
    if last_idx < len(timestamps):
        plt.plot(timestamps[last_idx:], values[last_idx:], color="blue", linewidth=1.2)

    # Final decorations
    plt.title(f"Signal: {signal}")
    plt.xlabel("Timestamp")
    plt.ylabel("Value")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()




import matplotlib.pyplot as plt
from pyspark.sql.functions import col
import pandas as pd

# Load anomaly DataFrame as Pandas â€” it's small
anomalydf = pd.read_csv("/dbfs/mnt/data/anomaly_windows_complex.csv")
anomalydf["start_timestamp"] = pd.to_datetime(anomalydf["start_timestamp"], format="%m/%d/%Y %H:%M:%S:%f")
anomalydf["end_timestamp"] = pd.to_datetime(anomalydf["end_timestamp"], format="%m/%d/%Y %H:%M:%S:%f")

# Get signal columns dynamically
signal_cols = [col_name for col_name in df.columns if col_name.startswith("signal_")]

# Loop through each signal column
for signal in signal_cols:
    # Select timestamp and this signal only, convert to Pandas
    small_df = df.select("timestamp", signal).toPandas()

    # Convert timestamp column
    small_df["timestamp"] = pd.to_datetime(small_df["timestamp"], format="%m/%d/%Y %H:%M:%S:%f")
    small_df = small_df.sort_values("timestamp").reset_index(drop=True)

    # Plot base scatter
    plt.figure(figsize=(10, 5))
    plt.scatter(small_df["timestamp"], small_df[signal], color="blue", s=5, label="Normal")

    # Overlay anomaly trends
    relevant_windows = anomalydf[anomalydf["signal"] == signal]
    for _, row in relevant_windows.iterrows():
        start_ts = row["start_timestamp"]
        end_ts = row["end_timestamp"]

        # Extract anomaly segment
        window_df = small_df[(small_df["timestamp"] >= start_ts) & (small_df["timestamp"] <= end_ts)]

        # Yellow anomaly line
        plt.plot(window_df["timestamp"], window_df[signal], color="yellow", linewidth=2, label="Anomaly Trend")

        # Red boundary lines
        plt.axvline(x=start_ts, color="red", linestyle="--", linewidth=1)
        plt.axvline(x=end_ts, color="red", linestyle="--", linewidth=1)

    # Final plot touches
    plt.title(f"Scatter Plot for {signal}")
    plt.xlabel("Timestamp")
    plt.ylabel("Value")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.legend()
    plt.show()

import matplotlib.pyplot as plt
import pandas as pd

# Load anomaly windows (already small)
anomalydf = pd.read_csv("/dbfs/mnt/data/anomaly_windows_complex.csv")
anomalydf["start_timestamp"] = pd.to_datetime(anomalydf["start_timestamp"], format="%m/%d/%Y %H:%M:%S:%f")
anomalydf["end_timestamp"] = pd.to_datetime(anomalydf["end_timestamp"], format="%m/%d/%Y %H:%M:%S:%f")

# Extract signal columns
signal_cols = [col_name for col_name in df.columns if col_name.startswith("signal_")]

# Loop through each signal (processing one at a time)
for signal in signal_cols:
    # Select timestamp and signal column only and convert to Pandas
    small_df = df.select("timestamp", signal).toPandas()

    # Parse timestamps
    small_df["timestamp"] = pd.to_datetime(small_df["timestamp"], format="%m/%d/%Y %H:%M:%S:%f")
    small_df = small_df.sort_values("timestamp").reset_index(drop=True)

    timestamps = small_df["timestamp"].values
    values = small_df[signal].values

    # Plot scatter points
    plt.figure(figsize=(10, 5))
    plt.scatter(timestamps, values, s=5, color="blue", label="Raw Data")

    # Filter anomaly windows for this signal
    windows = anomalydf[anomalydf["signal"] == signal].sort_values("start_timestamp")

    last_idx = 0
    for _, row in windows.iterrows():
        start_ts = row["start_timestamp"]
        end_ts = row["end_timestamp"]

        # Find the start and end indices in the full dataframe
        start_mask = small_df["timestamp"] >= start_ts
        end_mask = small_df["timestamp"] <= end_ts

        if start_mask.any() and end_mask.any():
            start_idx = start_mask.idxmax()
            end_idx = end_mask[::-1].idxmax()

            # Plot normal segment before this anomaly window
            if start_idx > last_idx:
                plt.plot(timestamps[last_idx:start_idx+1], values[last_idx:start_idx+1], color="gray", linewidth=1.5, label="Normal Trend" if last_idx == 0 else "")

            # Plot anomaly segment
            plt.plot(timestamps[start_idx:end_idx+1], values[start_idx:end_idx+1], color="yellow", linewidth=2, label="Anomaly Trend")

            # Red vertical lines at boundaries
            plt.axvline(x=start_ts, color="red", linestyle="--", linewidth=1)
            plt.axvline(x=end_ts, color="red", linestyle="--", linewidth=1)

            last_idx = end_idx + 1

    # Plot final normal segment after last anomaly
    if last_idx < len(timestamps):
        plt.plot(timestamps[last_idx:], values[last_idx:], color="gray", linewidth=1.5)

    # Final touches
    plt.title(f"Signal: {signal}")
    plt.xlabel("Timestamp")
    plt.ylabel("Value")
    plt.xticks(rotation=45)
    plt.legend(loc="upper right")
    plt.tight_layout()
    plt.show()


import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

anomalydf = pd.read_csv("/dbfs/mnt/data/anomaly_windows_complex.csv")
anomalydf["start_timestamp"] = pd.to_datetime(anomalydf["start_timestamp"], format="%m/%d/%Y %H:%M:%S:%f")
anomalydf["end_timestamp"] = pd.to_datetime(anomalydf["end_timestamp"], format="%m/%d/%Y %H:%M:%S:%f")

signal_cols = [col for col in df.columns if col.startswith("signal_")]

for signal in signal_cols:
    print(f"Processing {signal}...")

    small_df = df.select("timestamp", signal).toPandas()
    small_df["timestamp"] = pd.to_datetime(small_df["timestamp"], format="%m/%d/%Y %H:%M:%S:%f")
    small_df = small_df.sort_values("timestamp").reset_index(drop=True)

    timestamps = small_df["timestamp"].values
    values = small_df[signal].values

    plt.figure(figsize=(12, 5))
    plt.scatter(timestamps, values, s=5, color="blue", label="Raw Data")

    signal_windows = anomalydf[anomalydf["signal"] == signal].sort_values("start_timestamp")
    last_idx = 0
    for _, row in signal_windows.iterrows():
        start_ts = row["start_timestamp"]
        end_ts = row["end_timestamp"]

        start_mask = small_df["timestamp"] >= start_ts
        end_mask = small_df["timestamp"] <= end_ts

        if start_mask.any() and end_mask.any():
            start_idx = start_mask.idxmax()
            end_idx = end_mask[::-1].idxmax()

            if start_idx > last_idx:
                plt.plot(timestamps[last_idx:start_idx+1], values[last_idx:start_idx+1], color="gray", linewidth=1.5)

            plt.plot(timestamps[start_idx:end_idx+1], values[start_idx:end_idx+1], color="yellow", linewidth=2)
            plt.axvline(x=start_ts, color="red", linestyle="--", linewidth=1)
            plt.axvline(x=end_ts, color="red", linestyle="--", linewidth=1)

            last_idx = end_idx + 1

    if last_idx < len(timestamps):
        plt.plot(timestamps[last_idx:], values[last_idx:], color="gray", linewidth=1.5)

    plt.title(f"Time Series with Anomaly Windows: {signal}")
    plt.xlabel("Timestamp")
    plt.ylabel("Signal Value")
    plt.xticks(rotation=45)
    plt.legend()
    plt.tight_layout()
    plt.show()

    fft_vals = np.fft.fft(values)
    fft_freqs = np.fft.fftfreq(len(values), d=1)

    pos_mask = fft_freqs > 0
    freqs = fft_freqs[pos_mask]
    amplitudes = np.abs(fft_vals[pos_mask])

    plt.figure(figsize=(10, 4))
    plt.plot(freqs, amplitudes, color='purple')
    plt.title(f"FFT Spectrum of {signal}")
    plt.xlabel("Frequency (1/unit time)")
    plt.ylabel("Amplitude")
    plt.tight_layout()
    plt.show()



import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

sampling_interval = "1min"

time_unit_map = {
    "s": 1,
    "sec": 1,
    "second": 1,
    "min": 60,
    "minute": 60,
    "h": 3600,
    "hr": 3600,
    "hour": 3600
}

def parse_interval(interval_str):
    if interval_str.isdigit():
        return float(interval_str)
    num = ''.join([c for c in interval_str if c.isdigit()])
    unit = ''.join([c for c in interval_str if not c.isdigit()]).strip().lower()
    return float(num) * time_unit_map[unit]

d_seconds = parse_interval(sampling_interval)

signal_cols = [col for col in df.columns if col.startswith("signal_")]

for signal in signal_cols:
    small_df = df.select("timestamp", signal).toPandas()
    small_df["timestamp"] = pd.to_datetime(small_df["timestamp"], format="%m/%d/%Y %H:%M:%S:%f")
    small_df = small_df.sort_values("timestamp").reset_index(drop=True)

    values = small_df[signal].values
    fft_vals = np.fft.fft(values)
    fft_freqs = np.fft.fftfreq(len(values), d=d_seconds)

    pos_mask = fft_freqs > 0
    freqs = fft_freqs[pos_mask]
    amplitudes = np.abs(fft_vals[pos_mask])

    plt.figure(figsize=(10, 4))
    plt.plot(freqs, amplitudes, color='purple')
    plt.title(f"FFT Spectrum of {signal} ({sampling_interval} sampling)")
    plt.xlabel("Frequency (Hz)")
    plt.ylabel("Amplitude")
    plt.tight_layout()
    plt.show()



import pandas as pd
import numpy as np
from pyspark.sql import functions as F
import matplotlib.pyplot as plt

signal_cols = [col for col in df.columns if col.startswith("signal_")]

pdf = df.select(["timestamp"] + signal_cols).toPandas()
pdf["timestamp"] = pd.to_datetime(pdf["timestamp"], format="%m/%d/%Y %H:%M:%S:%f")
pdf = pdf.sort_values("timestamp").reset_index(drop=True)
pdf.set_index("timestamp", inplace=True)

zscore_threshold = 3
rolling_window = "100min"

for signal in signal_cols:
    series = pdf[signal]
    roll_mean = series.rolling(rolling_window).mean()
    roll_std = series.rolling(rolling_window).std()
    zscore = (series - roll_mean) / roll_std
    anomalies = zscore.abs() > zscore_threshold

    plt.figure(figsize=(12, 4))
    plt.plot(series.index, series, label="Raw", color="lightgray")
    plt.plot(roll_mean.index, roll_mean, label="Rolling Mean", color="blue")
    plt.scatter(series.index[anomalies], series[anomalies], color="red", label="Anomaly", s=10)
    plt.title(f"Rolling Anomaly Detection (100min) - {signal}")
    plt.legend()
    plt.tight_layout()
    plt.show()

