{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bfece30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Small set shapes: (799, 60) (200, 60) | LSTM windows: 770 171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Dense: {'lr': 0.001, 'batch': 512, 'epochs': 50, 'patience': 5, 'weight_decay': 0.0} val_loss: 0.02488909475505352\n",
      "Best LSTM : {'lr': 0.001, 'batch': 128, 'epochs': 50, 'patience': 5, 'hidden': 64, 'latent': 16, 'layers': 1} val_loss: 0.022485879353351064\n",
      "Saved: C:\\Users\\Ishaan Tiwari\\Desktop\\Kafka\\artifacts\\best_params.json\n",
      "Saved: C:\\Users\\Ishaan Tiwari\\Desktop\\Kafka\\artifacts\\scaler_prod.joblib\n",
      "Saved: C:\\Users\\Ishaan Tiwari\\Desktop\\Kafka\\artifacts\\features.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\Ishaan Tiwari\\Desktop\\Kafka\\artifacts\\dense_ae.pt\n",
      "Saved: C:\\Users\\Ishaan Tiwari\\Desktop\\Kafka\\artifacts\\lstm_ae.pt\n",
      "\n",
      "Artifacts saved:\n",
      " - C:\\Users\\Ishaan Tiwari\\Desktop\\Kafka\\artifacts\\scaler_small.joblib\n",
      " - C:\\Users\\Ishaan Tiwari\\Desktop\\Kafka\\artifacts\\scaler_prod.joblib\n",
      " - C:\\Users\\Ishaan Tiwari\\Desktop\\Kafka\\artifacts\\dense_ae.pt\n",
      " - C:\\Users\\Ishaan Tiwari\\Desktop\\Kafka\\artifacts\\lstm_ae.pt\n",
      " - C:\\Users\\Ishaan Tiwari\\Desktop\\Kafka\\artifacts\\best_params.json\n",
      " - C:\\Users\\Ishaan Tiwari\\Desktop\\Kafka\\artifacts\\features.json\n",
      " - C:\\Users\\Ishaan Tiwari\\Desktop\\Kafka\\artifacts\\training_report.json\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # PyTorch Autoencoder Training (Dense + LSTM) — Artifact Ready\n",
    "# \n",
    "# This notebook trains tabular (Dense AE) and sequence (LSTM AE) autoencoders\n",
    "# and saves all artifacts needed for streaming inference:\n",
    "# - artifacts/scaler_small.joblib\n",
    "# - artifacts/scaler_prod.joblib\n",
    "# - artifacts/dense_ae.pt\n",
    "# - artifacts/lstm_ae.pt\n",
    "# - artifacts/best_params.json (includes seq_len, stride)\n",
    "# - artifacts/features.json\n",
    "# - artifacts/training_report.json\n",
    "# \n",
    "# Edit SMALL_CSV / BIG_CSV paths as needed.\n",
    "\n",
    "# %%\n",
    "# 1) Imports & Global Config\n",
    "import os, json, random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "# Paths\n",
    "SMALL_CSV = \"Book1.csv\"   # small subset for hyperparam search (~50k–100k rows)\n",
    "BIG_CSV   = \"Book1.csv\"   # big dataset for final training (~600k)\n",
    "\n",
    "ARTIFACTS_DIR = Path(\"artifacts\")\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FEATURES = [f\"signal_{i}\" for i in range(1, 61)]\n",
    "TIMESTAMP_COL = \"Timestamp\"  # optional in CSV\n",
    "\n",
    "# Sequence defaults\n",
    "SEQ_LEN = 30\n",
    "STRIDE  = 1\n",
    "\n",
    "# %%\n",
    "# 2) Helpers: IO, datasets, models, training utilities\n",
    "\n",
    "def load_signals_csv(path, features=FEATURES, timestamp_col=TIMESTAMP_COL):\n",
    "    cols_in_file = pd.read_csv(path, nrows=0).columns.tolist()\n",
    "    usecols = [c for c in features if c in cols_in_file] + ([timestamp_col] if timestamp_col in cols_in_file else [])\n",
    "    df = pd.read_csv(path, usecols=usecols)\n",
    "    # Ensure full feature set in correct order (fill missing with 0.0 if any)\n",
    "    for f in features:\n",
    "        if f not in df.columns:\n",
    "            df[f] = 0.0\n",
    "    X = df[features].astype(\"float32\").values\n",
    "    return X\n",
    "\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X):\n",
    "        self.X = np.asarray(X, dtype=np.float32)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.X[idx])\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, X_scaled, seq_len=30, stride=1):\n",
    "        self.seq_len = seq_len; self.stride = stride\n",
    "        X = np.asarray(X_scaled, dtype=np.float32)\n",
    "        n = len(X)\n",
    "        if n < seq_len:\n",
    "            self.X_seq = np.empty((0, seq_len, X.shape[1]), dtype=np.float32)\n",
    "        else:\n",
    "            num = (n - seq_len) // stride + 1\n",
    "            self.X_seq = np.stack([X[i*stride:i*stride+seq_len] for i in range(num)], axis=0)\n",
    "    def __len__(self):\n",
    "        return len(self.X_seq)\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.X_seq[idx])\n",
    "\n",
    "class DenseAE(nn.Module):\n",
    "    def __init__(self, in_dim=60):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_dim, 40), nn.ReLU(),\n",
    "            nn.Linear(40, 20), nn.ReLU(),\n",
    "            nn.Linear(20, 10), nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(10, 20), nn.ReLU(),\n",
    "            nn.Linear(20, 40), nn.ReLU(),\n",
    "            nn.Linear(40, in_dim),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "\n",
    "class LSTMAE(nn.Module):\n",
    "    def __init__(self, input_dim=60, hidden_dim=64, latent_dim=16, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.to_latent = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.from_latent = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.decoder = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_dim, input_dim)\n",
    "    def forward(self, x):  # x: (B, T, F)\n",
    "        enc_out, _ = self.encoder(x)\n",
    "        h_last = enc_out[:, -1, :]\n",
    "        z = self.to_latent(h_last)\n",
    "        h0 = self.from_latent(z).unsqueeze(0)\n",
    "        c0 = torch.zeros_like(h0)\n",
    "        dec_out, _ = self.decoder(x, (h0, c0))\n",
    "        y = self.out(dec_out)\n",
    "        return y\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=5, min_delta=0.0):\n",
    "        self.patience = patience; self.min_delta = min_delta\n",
    "        self.best = float(\"inf\"); self.count = 0\n",
    "    def step(self, val):\n",
    "        if val < self.best - self.min_delta:\n",
    "            self.best = val; self.count = 0; return True\n",
    "        else:\n",
    "            self.count += 1; return False\n",
    "    def should_stop(self):\n",
    "        return self.count >= self.patience\n",
    "\n",
    "def make_loader(ds, batch_size=256, shuffle_flag=True):\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle_flag, drop_last=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "# %%\n",
    "# 3) Load SMALL CSV, split, fit scaler on TRAIN (small), build datasets\n",
    "X_small = load_signals_csv(SMALL_CSV, FEATURES, TIMESTAMP_COL)\n",
    "X_s_tr, X_s_va = train_test_split(X_small, test_size=0.2, random_state=SEED, shuffle=True)\n",
    "\n",
    "scaler_small = MinMaxScaler()\n",
    "Xs_tr = scaler_small.fit_transform(X_s_tr)\n",
    "Xs_va = scaler_small.transform(X_s_va)\n",
    "\n",
    "# Save small scaler for traceability\n",
    "joblib.dump(scaler_small, ARTIFACTS_DIR/\"scaler_small.joblib\")\n",
    "\n",
    "tr_ds_dense = TabularDataset(Xs_tr)\n",
    "va_ds_dense = TabularDataset(Xs_va)\n",
    "\n",
    "tr_ds_seq = SequenceDataset(Xs_tr, seq_len=SEQ_LEN, stride=STRIDE)\n",
    "va_ds_seq = SequenceDataset(Xs_va, seq_len=SEQ_LEN, stride=STRIDE)\n",
    "\n",
    "print(\"Small set shapes:\", Xs_tr.shape, Xs_va.shape, \"| LSTM windows:\", len(tr_ds_seq), len(va_ds_seq))\n",
    "\n",
    "# %%\n",
    "# 4) Hyperparam search (small): Dense AE + LSTM AE\n",
    "param_grid_dense = [\n",
    "    {\"lr\": 1e-3, \"batch\": 512, \"epochs\": 50, \"patience\": 5, \"weight_decay\": 0.0},\n",
    "    {\"lr\": 5e-4, \"batch\": 512, \"epochs\": 50, \"patience\": 5, \"weight_decay\": 1e-5},\n",
    "]\n",
    "param_grid_lstm = [\n",
    "    {\"lr\": 1e-3, \"batch\": 128, \"epochs\": 50, \"patience\": 5, \"hidden\": 64, \"latent\": 16, \"layers\": 1},\n",
    "    {\"lr\": 5e-4, \"batch\": 128, \"epochs\": 50, \"patience\": 5, \"hidden\": 96, \"latent\": 24, \"layers\": 1},\n",
    "]\n",
    "\n",
    "results = {\"dense\": [], \"lstm\": []}\n",
    "\n",
    "# Dense grid\n",
    "for p in param_grid_dense:\n",
    "    model = DenseAE(in_dim=60).to(DEVICE)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=p[\"lr\"], weight_decay=p.get(\"weight_decay\", 0.0))\n",
    "    crit = nn.MSELoss()\n",
    "    tr_loader = make_loader(tr_ds_dense, batch_size=p[\"batch\"], shuffle_flag=True)\n",
    "    va_loader = make_loader(va_ds_dense, batch_size=p[\"batch\"], shuffle_flag=False)\n",
    "    es = EarlyStopper(patience=p[\"patience\"], min_delta=0.0)\n",
    "\n",
    "    best_val = float(\"inf\"); best_state = None; no_improve = 0\n",
    "    for epoch in range(p[\"epochs\"]):\n",
    "        model.train(); tr_sum = 0.0; n_tr = 0\n",
    "        for xb in tr_loader:\n",
    "            xb = xb.to(DEVICE); opt.zero_grad(set_to_none=True)\n",
    "            recon = model(xb); loss = crit(recon, xb); loss.backward(); opt.step()\n",
    "            tr_sum += loss.item()*xb.size(0); n_tr += xb.size(0)\n",
    "        model.eval(); va_sum = 0.0; n_va = 0\n",
    "        with torch.no_grad():\n",
    "            for xb in va_loader:\n",
    "                xb = xb.to(DEVICE)\n",
    "                recon = model(xb); loss = crit(recon, xb)\n",
    "                va_sum += loss.item()*xb.size(0); n_va += xb.size(0)\n",
    "        va_loss = va_sum / max(1, n_va)\n",
    "        if va_loss < best_val - 1e-8:\n",
    "            best_val = va_loss\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= p[\"patience\"]:\n",
    "                break\n",
    "    results[\"dense\"].append({\"params\": p, \"val_loss\": best_val, \"state\": best_state})\n",
    "\n",
    "# LSTM grid\n",
    "for p in param_grid_lstm:\n",
    "    model = LSTMAE(input_dim=60, hidden_dim=p[\"hidden\"], latent_dim=p[\"latent\"], num_layers=p[\"layers\"]).to(DEVICE)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=p[\"lr\"]) \n",
    "    crit = nn.MSELoss()\n",
    "    tr_loader = make_loader(tr_ds_seq, batch_size=p[\"batch\"], shuffle_flag=True)\n",
    "    va_loader = make_loader(va_ds_seq, batch_size=p[\"batch\"], shuffle_flag=False)\n",
    "    es = EarlyStopper(patience=p[\"patience\"], min_delta=0.0)\n",
    "\n",
    "    best_val = float(\"inf\"); best_state = None; no_improve = 0\n",
    "    for epoch in range(p[\"epochs\"]):\n",
    "        model.train(); tr_sum = 0.0; n_tr = 0\n",
    "        for xb in tr_loader:\n",
    "            xb = xb.to(DEVICE)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            recon = model(xb); loss = crit(recon, xb); loss.backward(); opt.step()\n",
    "            tr_sum += loss.item()*xb.size(0); n_tr += xb.size(0)\n",
    "        model.eval(); va_sum = 0.0; n_va = 0\n",
    "        with torch.no_grad():\n",
    "            for xb in va_loader:\n",
    "                xb = xb.to(DEVICE)\n",
    "                recon = model(xb); loss = crit(recon, xb)\n",
    "                va_sum += loss.item()*xb.size(0); n_va += xb.size(0)\n",
    "        va_loss = va_sum / max(1, n_va)\n",
    "        if va_loss < best_val - 1e-8:\n",
    "            best_val = va_loss\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= p[\"patience\"]:\n",
    "                break\n",
    "    results[\"lstm\"].append({\"params\": p, \"val_loss\": best_val, \"state\": best_state})\n",
    "\n",
    "# %%\n",
    "# 5) Select best configs; save best_params & small scaler path\n",
    "best_dense = min(results[\"dense\"], key=lambda d: d[\"val_loss\"]) \n",
    "best_lstm  = min(results[\"lstm\"],  key=lambda d: d[\"val_loss\"]) \n",
    "print(\"Best Dense:\", best_dense[\"params\"], \"val_loss:\", best_dense[\"val_loss\"]) \n",
    "print(\"Best LSTM :\", best_lstm[\"params\"],  \"val_loss:\", best_lstm[\"val_loss\"]) \n",
    "\n",
    "with open(ARTIFACTS_DIR/\"best_params.json\",\"w\") as f:\n",
    "    json.dump({\n",
    "        \"dense\": best_dense[\"params\"],\n",
    "        \"lstm\":  best_lstm[\"params\"],\n",
    "        \"seq_len\": SEQ_LEN,\n",
    "        \"stride\":  STRIDE\n",
    "    }, f, indent=2)\n",
    "print(\"Saved:\", (ARTIFACTS_DIR/\"best_params.json\").resolve())\n",
    "\n",
    "# %%\n",
    "# 6) Load BIG CSV, split, fit PRODUCTION scaler, save scaler & features\n",
    "X_big = load_signals_csv(BIG_CSV, FEATURES, TIMESTAMP_COL)\n",
    "Xb_tr, Xb_val = train_test_split(X_big, test_size=0.2, random_state=SEED, shuffle=True)\n",
    "\n",
    "scaler_prod = MinMaxScaler()\n",
    "Xb_tr_s = scaler_prod.fit_transform(Xb_tr)\n",
    "Xb_val_s = scaler_prod.transform(Xb_val)\n",
    "\n",
    "joblib.dump(scaler_prod, ARTIFACTS_DIR/\"scaler_prod.joblib\")\n",
    "with open(ARTIFACTS_DIR/\"features.json\",\"w\") as f:\n",
    "    json.dump({\"features\": FEATURES, \"timestamp_col\": TIMESTAMP_COL}, f, indent=2)\n",
    "print(\"Saved:\", (ARTIFACTS_DIR/\"scaler_prod.joblib\").resolve())\n",
    "print(\"Saved:\", (ARTIFACTS_DIR/\"features.json\").resolve())\n",
    "\n",
    "# %%\n",
    "# 7) FINAL TRAIN — Dense AE on BIG set; save state_dict\n",
    "pdense = best_dense[\"params\"]\n",
    "dense_final = DenseAE(in_dim=60).to(DEVICE)\n",
    "opt = torch.optim.AdamW(dense_final.parameters(), lr=pdense[\"lr\"], weight_decay=pdense.get(\"weight_decay\", 0.0))\n",
    "crit = nn.MSELoss()\n",
    "tr_loader = make_loader(TabularDataset(Xb_tr_s), batch_size=pdense[\"batch\"], shuffle_flag=True)\n",
    "va_loader = make_loader(TabularDataset(Xb_val_s), batch_size=pdense[\"batch\"], shuffle_flag=False)\n",
    "\n",
    "best_val = float(\"inf\"); best_state = None; patience = int(pdense.get(\"patience\",5)); epochs = int(pdense.get(\"epochs\",50)); no_improve = 0\n",
    "for epoch in range(epochs):\n",
    "    # train\n",
    "    dense_final.train(); tr_sum=0.0; n_tr=0\n",
    "    for xb in tr_loader:\n",
    "        xb = xb.to(DEVICE); opt.zero_grad(set_to_none=True)\n",
    "        recon = dense_final(xb); loss = crit(recon, xb); loss.backward(); opt.step()\n",
    "        tr_sum += loss.item()*xb.size(0); n_tr += xb.size(0)\n",
    "    # val\n",
    "    dense_final.eval(); va_sum=0.0; n_va=0\n",
    "    with torch.no_grad():\n",
    "        for xb in va_loader:\n",
    "            xb = xb.to(DEVICE); recon = dense_final(xb); loss = crit(recon, xb)\n",
    "            va_sum += loss.item()*xb.size(0); n_va += xb.size(0)\n",
    "    va_loss = va_sum / max(1, n_va)\n",
    "    if va_loss < best_val - 1e-8:\n",
    "        best_val = va_loss\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in dense_final.state_dict().items()}\n",
    "        no_improve = 0\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= patience:\n",
    "            break\n",
    "\n",
    "if best_state is not None:\n",
    "    dense_final.load_state_dict(best_state)\n",
    "torch.save(dense_final.state_dict(), ARTIFACTS_DIR/\"dense_ae.pt\")\n",
    "print(\"Saved:\", (ARTIFACTS_DIR/\"dense_ae.pt\").resolve())\n",
    "\n",
    "# Update training report\n",
    "drep_path = ARTIFACTS_DIR/\"training_report.json\"\n",
    "try:\n",
    "    drep = json.load(open(drep_path))\n",
    "except FileNotFoundError:\n",
    "    drep = {}\n",
    "drep[\"dense\"] = {\"best_val\": float(best_val)}\n",
    "json.dump(drep, open(drep_path, \"w\"), indent=2)\n",
    "\n",
    "# %%\n",
    "# 8) FINAL TRAIN — LSTM AE on BIG set; save state_dict\n",
    "plstm = best_lstm[\"params\"]\n",
    "tr_seq = SequenceDataset(Xb_tr_s, seq_len=SEQ_LEN, stride=STRIDE)\n",
    "va_seq = SequenceDataset(Xb_val_s, seq_len=SEQ_LEN, stride=STRIDE)\n",
    "\n",
    "lstm_final = LSTMAE(input_dim=60, hidden_dim=int(plstm.get(\"hidden\",64)),\n",
    "                    latent_dim=int(plstm.get(\"latent\",16)), num_layers=int(plstm.get(\"layers\",1))).to(DEVICE)\n",
    "opt = torch.optim.AdamW(lstm_final.parameters(), lr=plstm[\"lr\"]) \n",
    "crit = nn.MSELoss()\n",
    "tr_loader = make_loader(tr_seq, batch_size=plstm[\"batch\"], shuffle_flag=True)\n",
    "va_loader = make_loader(va_seq, batch_size=plstm[\"batch\"], shuffle_flag=False)\n",
    "\n",
    "best_val = float(\"inf\"); best_state = None; patience = int(plstm.get(\"patience\",5)); epochs = int(plstm.get(\"epochs\",50)); no_improve = 0\n",
    "for epoch in range(epochs):\n",
    "    # train\n",
    "    lstm_final.train(); tr_sum=0.0; n_tr=0\n",
    "    for xb in tr_loader:\n",
    "        xb = xb.to(DEVICE); opt.zero_grad(set_to_none=True)\n",
    "        recon = lstm_final(xb); loss = crit(recon, xb); loss.backward(); opt.step()\n",
    "        tr_sum += loss.item()*xb.size(0); n_tr += xb.size(0)\n",
    "    # val\n",
    "    lstm_final.eval(); va_sum=0.0; n_va=0\n",
    "    with torch.no_grad():\n",
    "        for xb in va_loader:\n",
    "            xb = xb.to(DEVICE); recon = lstm_final(xb); loss = crit(recon, xb)\n",
    "            va_sum += loss.item()*xb.size(0); n_va += xb.size(0)\n",
    "    va_loss = va_sum / max(1, n_va)\n",
    "    if va_loss < best_val - 1e-8:\n",
    "        best_val = va_loss\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in lstm_final.state_dict().items()}\n",
    "        no_improve = 0\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= patience:\n",
    "            break\n",
    "\n",
    "if best_state is not None:\n",
    "    lstm_final.load_state_dict(best_state)\n",
    "torch.save(lstm_final.state_dict(), ARTIFACTS_DIR/\"lstm_ae.pt\")\n",
    "print(\"Saved:\", (ARTIFACTS_DIR/\"lstm_ae.pt\").resolve())\n",
    "\n",
    "# Update training report & ensure best_params includes seq\n",
    "try:\n",
    "    rep = json.load(open(drep_path))\n",
    "except FileNotFoundError:\n",
    "    rep = {}\n",
    "rep[\"lstm\"] = {\"best_val\": float(best_val), \"seq_len\": int(SEQ_LEN), \"stride\": int(STRIDE)}\n",
    "json.dump(rep, open(drep_path, \"w\"), indent=2)\n",
    "\n",
    "with open(ARTIFACTS_DIR/\"best_params.json\",\"w\") as f:\n",
    "    json.dump({\n",
    "        \"dense\": best_dense[\"params\"],\n",
    "        \"lstm\":  best_lstm[\"params\"],\n",
    "        \"seq_len\": SEQ_LEN,\n",
    "        \"stride\":  STRIDE\n",
    "    }, f, indent=2)\n",
    "\n",
    "# %%\n",
    "# 9) Summary of saved artifacts\n",
    "print(\"\\nArtifacts saved:\")\n",
    "for p in [\n",
    "    ARTIFACTS_DIR/\"scaler_small.joblib\",\n",
    "    ARTIFACTS_DIR/\"scaler_prod.joblib\",\n",
    "    ARTIFACTS_DIR/\"dense_ae.pt\",\n",
    "    ARTIFACTS_DIR/\"lstm_ae.pt\",\n",
    "    ARTIFACTS_DIR/\"best_params.json\",\n",
    "    ARTIFACTS_DIR/\"features.json\",\n",
    "    ARTIFACTS_DIR/\"training_report.json\",\n",
    "]:\n",
    "    print(\" -\", p.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210c0053",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
